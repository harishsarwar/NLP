{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1fbdd829-53dc-490f-94a2-c6007cdc2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "42450731-9e62-41a9-9e57-c940e72323b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "there\n",
      ".\n",
      "how\n",
      "are\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "# 1 spacy pipeline component (blank).\n",
    "nlp = spacy.blank('en')\n",
    "doc = nlp('hey there . how are you')\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "107e5a58-064c-4d0a-bab6-8cbd90d6abd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see its a blank pipe line.\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c39edda-aacd-41aa-a525-8ebc333cde45",
   "metadata": {},
   "source": [
    "# pre trained spacy pipeline components\n",
    "there are so any language and each having different pipe component.\n",
    "for english we have to install (python -m spacy download en_core_web_sm ) this command in command prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1e5f8b8d-1a5c-42e8-9fae-4cb7231e4072",
   "metadata": {},
   "outputs": [],
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "044c407d-35cf-4eb3-8400-7d29c9539d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "        # spacy pre_trained pipe line component for english language.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6a921e0c-6078-4ee8-ac3d-42d371c0c847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names\n",
    "# see all the pipe line components of spacy pre_processing for english language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c536e8b6-af84-4757-86d7-58b35acb8309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey  |  INTJ  |  hey\n",
      "there  |  ADV  |  there\n",
      ".  |  PUNCT  |  .\n",
      "how  |  SCONJ  |  how\n",
      "are  |  AUX  |  be\n",
      "you  |  PRON  |  you\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('hey there . how are you')\n",
    "for token in doc:\n",
    "    print(token, ' | ', token.pos_, ' | ', token.lemma_)\n",
    "            # here tagge gives pos_(pasrt of speech), lemmatizer gives(lemma_)\n",
    "            # pos_ : tells verb and grammer, lemma_ : gives the first verb of word(ig: ate = eat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33421c46-fae6-4599-b44a-47a024f4e369",
   "metadata": {},
   "source": [
    "# Name entity recongnization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "29bc87cf-5821-4995-a720-db785d915c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla inc  |  ORG\n",
      "$45 billion  |  MONEY\n"
     ]
    }
   ],
   "source": [
    "# nlp.pipe_names shows ner: means name entity recognization.\n",
    "doc = nlp('tesla inc is going to acquire twitter for $45 billion')\n",
    "for ent in doc.ents: # ents = entity\n",
    "    print(ent.text, ' | ', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5a5a39de-8c42-4a4e-88f2-7f4daf711715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tesla inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to acquire twitter for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with visual repersentation.\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style = 'ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f32bb-e0c3-4dd2-a08f-00758e9d33b1",
   "metadata": {},
   "source": [
    "# customizing blank pipe line \n",
    "add component from enlish language ner(name entity recognization) for blank pipe line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9accf6a5-efe9-401d-beed-22828965ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "doc = nlp('tesla is going to avquire twitter for $45 billion')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ' | ', ent.label_)\n",
    "\n",
    "# dont go any think bcs this is spacy blak pipe line \n",
    "# lats add (ner) pipe line component of english laguage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c18b2eec-b18e-4788-8ac4-acff4bafb812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding (ner) pipe line component in blank pipe line.\n",
    "source_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "nlp.add_pipe('ner', source=source_nlp)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "adaa1569-64ee-4f0e-926c-5052e1d85156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla  |  ORG\n",
      "$45 billion  |  MONEY\n"
     ]
    }
   ],
   "source": [
    "# successfully add ner pipeline component in blacn pipe line\n",
    "doc = nlp('tesla is going to acquire twitter for $45 billion')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ' | ', ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882b99d-daf8-4b36-be9c-f3f8c1461d56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
